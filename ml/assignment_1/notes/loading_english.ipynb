{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the English file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_file = open(\"english.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ```<file_object>.readlines()```, we can load the data in a way where each line within the text file is an individual element within a list. I show the first 10 elements of the ```readlines()``` output for your visual purposes. We can see that these elements are the same as the first 10 lines within the english.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a\\n', 'aa\\n', 'aaa\\n', 'aachen\\n', 'aardvark\\n', 'aardvarks\\n', 'aardwolf\\n', 'aardwolves\\n', 'aarhus\\n', 'aaron\\n']\n"
     ]
    }
   ],
   "source": [
    "english_lines = english_file.readlines()\n",
    "print(english_lines[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data is quite noisy. At the end of each word is a new-line character represented by ```'\\n'```. We can remove this through a string function called ```replace()```, replacing new-line character ```\\n``` with the empty string ```''```. The following code block is just temporary code for your visual purposes of seeing the words cleansed of the ```\\n```. character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aa', 'aaa', 'aachen', 'aardvark', 'aardvarks', 'aardwolf', 'aardwolves', 'aarhus', 'aaron']\n"
     ]
    }
   ],
   "source": [
    "print([s.replace('\\n', '') for s in english_lines[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this in loading our English data into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = []\n",
    "target_dataset = []\n",
    "\n",
    "for word in english_lines:\n",
    "    # Clean the line by removing the new-line character\n",
    "    cleaned_word = word.replace('\\n', '')\n",
    "    \n",
    "    # Check if the length of the cleaned word is equal to 7, to get words with 7 characters.\n",
    "    if len(cleaned_word) == 7:\n",
    "        # Make an array for converting word to ord representation\n",
    "        word_to_ord = []\n",
    "        \n",
    "        # Iterate through the cleaned word characters, ord the character, and append it to the word_to_ord list.\n",
    "        for char in cleaned_word:\n",
    "            word_to_ord.append(ord(char))\n",
    "            \n",
    "        # Append the ord'ed word to the training dataset\n",
    "        training_dataset.append(word_to_ord)\n",
    "        \n",
    "        # Append the correct answer to the target dataset\n",
    "        target_dataset.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we get what we want, ```ord()``` list representations of words within a bigger list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 training data:\n",
      "[97, 97, 114, 111, 110, 105, 99]\n",
      "[97, 98, 97, 99, 116, 111, 114]\n",
      "[97, 98, 97, 100, 100, 111, 110]\n",
      "[97, 98, 97, 108, 111, 110, 101]\n",
      "[97, 98, 97, 110, 100, 111, 110]\n",
      "[97, 98, 97, 115, 104, 101, 100]\n",
      "[97, 98, 97, 115, 104, 101, 115]\n",
      "[97, 98, 97, 115, 105, 110, 103]\n",
      "[97, 98, 97, 116, 105, 110, 103]\n",
      "[97, 98, 97, 116, 111, 114, 115]\n",
      "\n",
      "First 10 target data: \n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"First 10 training data:\")\n",
    "for word in training_dataset[:10]: print(word)\n",
    "    \n",
    "print(f\"\\nFirst 10 target data: \\n{target_dataset[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code was very explicit to accomodate for comments. A much shorter version of doing the same thing is below (this is how I would code it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = []\n",
    "target_dataset = []\n",
    "\n",
    "for line in english_lines:\n",
    "    line = line.replace('\\n', '')\n",
    "    \n",
    "    if len(line) == 7:\n",
    "        training_dataset.append([ord(char) for char in line])\n",
    "        target_dataset.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this code is functionally the same as the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 training data:\n",
      "[97, 97, 114, 111, 110, 105, 99]\n",
      "[97, 98, 97, 99, 116, 111, 114]\n",
      "[97, 98, 97, 100, 100, 111, 110]\n",
      "[97, 98, 97, 108, 111, 110, 101]\n",
      "[97, 98, 97, 110, 100, 111, 110]\n",
      "[97, 98, 97, 115, 104, 101, 100]\n",
      "[97, 98, 97, 115, 104, 101, 115]\n",
      "[97, 98, 97, 115, 105, 110, 103]\n",
      "[97, 98, 97, 116, 105, 110, 103]\n",
      "[97, 98, 97, 116, 111, 114, 115]\n",
      "\n",
      "First 10 target data: \n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"First 10 training data:\")\n",
    "for word in training_dataset[:10]: print(word)\n",
    "    \n",
    "print(f\"\\nFirst 10 target data: \\n{target_dataset[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hope this helps!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:IntroML]",
   "language": "python",
   "name": "conda-env-IntroML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
