{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating simple artificial intelligence in Python\n",
    "\n",
    "In this tutorial, we will be classifying what type of Iris a set of values are. Is it setosa, versicolor, or virginica? Using sklearn, we will be doing this automatically, and hopefully be able to predict a certain species of flower *even if we don't know specifically what the species is*. \n",
    "\n",
    "#### Step 1: Data Preparation\n",
    "First, we need to load our data from a file. We need to separate them into two arrays: \n",
    "\n",
    "- Training Array (often denoted as \"X\")\n",
    "    - Your training array will contain a set of values. In our example, we will be passing the sepal length and width, and petal length and width.\n",
    "- Target Array (often denoted as \"y\")\n",
    "    - Your target array will contain the *answers* to the given training array.\n",
    "\n",
    "For simplicity, I will be using the following English vs. German example:\n",
    "\n",
    "|Training Array|Target Array|\n",
    "|-----|-----|\n",
    "|ANYONE|English|\n",
    "|UPROAR|English|\n",
    "|YELLOW|English|\n",
    "|BÄRGET|German|\n",
    "|ZURUFE|German|\n",
    "|WÜSTEM|German|\n",
    "\n",
    "Unlike the above example, we are going to be using Iris data instead. First, let's create our training array. We shall be using the traditional way of loading data in Python, in contrast to `pandas`, for reference and simplicity.\n",
    "\n",
    "##### Traditionally loading files in Python\n",
    "You can open files natively, without the need of libraries, using the `open()` function. `open()` returns a file-like object. In this case, it returns a TextIOWrapper object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_io.TextIOWrapper'>\n"
     ]
    }
   ],
   "source": [
    "my_file = open(\"iris-setosa.csv\", 'r')\n",
    "print(type(my_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to read a TextIOWrapper object, you can use `read()` or `readlines()`.\n",
    "\n",
    "Here, we will use `readlines()`. Readlines returns a list of strings, with each element being the corresponding line within the text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length,sepal_width,petal_length,petal_width,species\n",
      "\n",
      "5.1,3.5,1.4,0.2,Iris-setosa\n",
      "\n",
      "4.9,3.0,1.4,0.2,Iris-setosa\n",
      "\n",
      "4.7,3.2,1.3,0.2,Iris-setosa\n",
      "\n",
      "4.6,3.1,1.5,0.2,Iris-setosa\n",
      "\n",
      "5.0,3.6,1.4,0.2,Iris-setosa\n",
      "\n",
      "5.4,3.9,1.7,0.4,Iris-setosa\n",
      "\n",
      "4.6,3.4,1.4,0.3,Iris-setosa\n",
      "\n",
      "5.0,3.4,1.5,0.2,Iris-setosa\n",
      "\n",
      "4.4,2.9,1.4,0.2,Iris-setosa\n",
      "\n",
      "4.9,3.1,1.5,0.1,Iris-setosa\n",
      "\n",
      "5.4,3.7,1.5,0.2,Iris-setosa\n",
      "\n",
      "4.8,3.4,1.6,0.2,Iris-setosa\n",
      "\n",
      "4.8,3.0,1.4,0.1,Iris-setosa\n",
      "\n",
      "4.3,3.0,1.1,0.1,Iris-setosa\n",
      "\n",
      "5.8,4.0,1.2,0.2,Iris-setosa\n",
      "\n",
      "5.7,4.4,1.5,0.4,Iris-setosa\n",
      "\n",
      "5.4,3.9,1.3,0.4,Iris-setosa\n",
      "\n",
      "5.1,3.5,1.4,0.3,Iris-setosa\n",
      "\n",
      "5.7,3.8,1.7,0.3,Iris-setosa\n",
      "\n",
      "5.1,3.8,1.5,0.3,Iris-setosa\n",
      "\n",
      "5.4,3.4,1.7,0.2,Iris-setosa\n",
      "\n",
      "5.1,3.7,1.5,0.4,Iris-setosa\n",
      "\n",
      "4.6,3.6,1.0,0.2,Iris-setosa\n",
      "\n",
      "5.1,3.3,1.7,0.5,Iris-setosa\n",
      "\n",
      "4.8,3.4,1.9,0.2,Iris-setosa\n",
      "\n",
      "5.0,3.0,1.6,0.2,Iris-setosa\n",
      "\n",
      "5.0,3.4,1.6,0.4,Iris-setosa\n",
      "\n",
      "5.2,3.5,1.5,0.2,Iris-setosa\n",
      "\n",
      "5.2,3.4,1.4,0.2,Iris-setosa\n",
      "\n",
      "4.7,3.2,1.6,0.2,Iris-setosa\n",
      "\n",
      "4.8,3.1,1.6,0.2,Iris-setosa\n",
      "\n",
      "5.4,3.4,1.5,0.4,Iris-setosa\n",
      "\n",
      "5.2,4.1,1.5,0.1,Iris-setosa\n",
      "\n",
      "5.5,4.2,1.4,0.2,Iris-setosa\n",
      "\n",
      "4.9,3.1,1.5,0.1,Iris-setosa\n",
      "\n",
      "5.0,3.2,1.2,0.2,Iris-setosa\n",
      "\n",
      "5.5,3.5,1.3,0.2,Iris-setosa\n",
      "\n",
      "4.9,3.1,1.5,0.1,Iris-setosa\n",
      "\n",
      "4.4,3.0,1.3,0.2,Iris-setosa\n",
      "\n",
      "5.1,3.4,1.5,0.2,Iris-setosa\n",
      "\n",
      "5.0,3.5,1.3,0.3,Iris-setosa\n",
      "\n",
      "4.5,2.3,1.3,0.3,Iris-setosa\n",
      "\n",
      "4.4,3.2,1.3,0.2,Iris-setosa\n",
      "\n",
      "5.0,3.5,1.6,0.6,Iris-setosa\n",
      "\n",
      "5.1,3.8,1.9,0.4,Iris-setosa\n",
      "\n",
      "4.8,3.0,1.4,0.3,Iris-setosa\n",
      "\n",
      "5.1,3.8,1.6,0.2,Iris-setosa\n",
      "\n",
      "4.6,3.2,1.4,0.2,Iris-setosa\n",
      "\n",
      "5.3,3.7,1.5,0.2,Iris-setosa\n",
      "\n",
      "5.0,3.3,1.4,0.2,Iris-setosa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text_line in my_file:\n",
    "    print(text_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using what we learnt about glob from yesterday, we can go ahead and load all of the files in a loop. Instead of using pandas, however, we will be using the same method that we used above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity: Read multiple files using glob, and append all values into a list\n",
    "\n",
    "So, using the notebook that we used yesterday, go ahead and create a cell that will load all `*.csv`s into an array and append each line into a *singular list*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most succinct way to do this, without being to obtuse, is this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "training = []\n",
    "target = []\n",
    "label_dict = {}\n",
    "\n",
    "for item in glob.glob(\"*.csv\"):\n",
    "    lines = open(item, 'r').readlines()\n",
    "    del lines[0]\n",
    "    for line in lines:\n",
    "        training_slice = line.split(\",\")[:-1]\n",
    "        slice_to_float = [float(i) for i in training_slice]\n",
    "        training.append(slice_to_float)\n",
    "        label = line.split(\",\")[-1].replace(\"\\n\", '')\n",
    "        try:\n",
    "            target.append(label_dict[label])\n",
    "        except KeyError:\n",
    "            label_dict[label] = len(label_dict)\n",
    "            target.append(label_dict[label])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now we have both of our training and target arrays prepared. Now, let's do some simple machine learning!\n",
    "\n",
    "First, we need to import certain scripts/functions from the `sklearn` library, which stands for SciKit Learn. We can do that using the `from ... import ...` statement.\n",
    "\n",
    "The above allows you to import only *specific* things within the library, instead of the entire thing. This can help in terms of memory management and performance of your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `sklearn` is incredibly easy, and creating a neural network can be done in two lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the MLPClassifier\n",
    "mlp_nn = MLPClassifier()\n",
    "\n",
    "# Fit (or train) the MLPClassifier with the training\n",
    "# and corresponding target data.\n",
    "mlp_nn.fit(training, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_nn.predict([training[145]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
